{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "lastClass.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "EC1JPGe_i-Iu"
      },
      "outputs": [],
      "source": [
        "# 필요한 라이브러리 로딩\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.callbacks import ModelCheckpoint, EarlyStopping"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "CUY-ywRUmCtp"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# seed 값 고정\n",
        "seed = 0\n",
        "np.random.seed(seed)\n",
        "tf.random.set_seed(3)"
      ],
      "metadata": {
        "id": "yYGadBfamNmp"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tmp_df = pd.read_csv('/content/wine.csv', header=None)"
      ],
      "metadata": {
        "id": "7GZExdrnmZVo"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = tmp_df.sample(frac=1)\n",
        "df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "QcU0hxAEmoIw",
        "outputId": "82cfae0b-1dff-41fd-fac4-592c85ba6ab8"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "       0      1     2     3      4     5      6        7     8     9     10  \\\n",
              "169   7.5  0.705  0.24  1.80  0.360  15.0   63.0  0.99640  3.00  1.59   9.5   \n",
              "1045  6.9  0.440  0.00  1.40  0.070  32.0   38.0  0.99438  3.32  0.58  11.4   \n",
              "5178  7.4  0.250  0.28  7.25  0.028  14.0   78.0  0.99238  2.94  0.37  11.5   \n",
              "2481  7.4  0.260  0.43  6.00  0.022  22.0  125.0  0.99280  3.13  0.55  11.5   \n",
              "2631  7.1  0.300  0.36  6.80  0.055  44.5  234.0  0.99720  3.49  0.64  10.2   \n",
              "...   ...    ...   ...   ...    ...   ...    ...      ...   ...   ...   ...   \n",
              "4463  5.3  0.160  0.39  1.00  0.028  40.0  101.0  0.99156  3.57  0.59  10.6   \n",
              "958   6.4  0.570  0.12  2.30  0.120  25.0   36.0  0.99519  3.47  0.71  11.3   \n",
              "5807  5.6  0.230  0.29  3.10  0.023  19.0   89.0  0.99068  3.25  0.51  11.2   \n",
              "4006  7.6  0.310  0.27  5.80  0.036  23.0  109.0  0.99399  3.34  0.54  11.0   \n",
              "6401  5.8  0.280  0.34  2.20  0.037  24.0  125.0  0.98986  3.36  0.33  12.8   \n",
              "\n",
              "      11  12  \n",
              "169    5   1  \n",
              "1045   6   1  \n",
              "5178   7   0  \n",
              "2481   6   0  \n",
              "2631   6   0  \n",
              "...   ..  ..  \n",
              "4463   6   0  \n",
              "958    7   1  \n",
              "5807   6   0  \n",
              "4006   6   0  \n",
              "6401   8   0  \n",
              "\n",
              "[6497 rows x 13 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-207b778d-efa5-4da6-b330-7df37a6be0fa\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>10</th>\n",
              "      <th>11</th>\n",
              "      <th>12</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>169</th>\n",
              "      <td>7.5</td>\n",
              "      <td>0.705</td>\n",
              "      <td>0.24</td>\n",
              "      <td>1.80</td>\n",
              "      <td>0.360</td>\n",
              "      <td>15.0</td>\n",
              "      <td>63.0</td>\n",
              "      <td>0.99640</td>\n",
              "      <td>3.00</td>\n",
              "      <td>1.59</td>\n",
              "      <td>9.5</td>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1045</th>\n",
              "      <td>6.9</td>\n",
              "      <td>0.440</td>\n",
              "      <td>0.00</td>\n",
              "      <td>1.40</td>\n",
              "      <td>0.070</td>\n",
              "      <td>32.0</td>\n",
              "      <td>38.0</td>\n",
              "      <td>0.99438</td>\n",
              "      <td>3.32</td>\n",
              "      <td>0.58</td>\n",
              "      <td>11.4</td>\n",
              "      <td>6</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5178</th>\n",
              "      <td>7.4</td>\n",
              "      <td>0.250</td>\n",
              "      <td>0.28</td>\n",
              "      <td>7.25</td>\n",
              "      <td>0.028</td>\n",
              "      <td>14.0</td>\n",
              "      <td>78.0</td>\n",
              "      <td>0.99238</td>\n",
              "      <td>2.94</td>\n",
              "      <td>0.37</td>\n",
              "      <td>11.5</td>\n",
              "      <td>7</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2481</th>\n",
              "      <td>7.4</td>\n",
              "      <td>0.260</td>\n",
              "      <td>0.43</td>\n",
              "      <td>6.00</td>\n",
              "      <td>0.022</td>\n",
              "      <td>22.0</td>\n",
              "      <td>125.0</td>\n",
              "      <td>0.99280</td>\n",
              "      <td>3.13</td>\n",
              "      <td>0.55</td>\n",
              "      <td>11.5</td>\n",
              "      <td>6</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2631</th>\n",
              "      <td>7.1</td>\n",
              "      <td>0.300</td>\n",
              "      <td>0.36</td>\n",
              "      <td>6.80</td>\n",
              "      <td>0.055</td>\n",
              "      <td>44.5</td>\n",
              "      <td>234.0</td>\n",
              "      <td>0.99720</td>\n",
              "      <td>3.49</td>\n",
              "      <td>0.64</td>\n",
              "      <td>10.2</td>\n",
              "      <td>6</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4463</th>\n",
              "      <td>5.3</td>\n",
              "      <td>0.160</td>\n",
              "      <td>0.39</td>\n",
              "      <td>1.00</td>\n",
              "      <td>0.028</td>\n",
              "      <td>40.0</td>\n",
              "      <td>101.0</td>\n",
              "      <td>0.99156</td>\n",
              "      <td>3.57</td>\n",
              "      <td>0.59</td>\n",
              "      <td>10.6</td>\n",
              "      <td>6</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>958</th>\n",
              "      <td>6.4</td>\n",
              "      <td>0.570</td>\n",
              "      <td>0.12</td>\n",
              "      <td>2.30</td>\n",
              "      <td>0.120</td>\n",
              "      <td>25.0</td>\n",
              "      <td>36.0</td>\n",
              "      <td>0.99519</td>\n",
              "      <td>3.47</td>\n",
              "      <td>0.71</td>\n",
              "      <td>11.3</td>\n",
              "      <td>7</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5807</th>\n",
              "      <td>5.6</td>\n",
              "      <td>0.230</td>\n",
              "      <td>0.29</td>\n",
              "      <td>3.10</td>\n",
              "      <td>0.023</td>\n",
              "      <td>19.0</td>\n",
              "      <td>89.0</td>\n",
              "      <td>0.99068</td>\n",
              "      <td>3.25</td>\n",
              "      <td>0.51</td>\n",
              "      <td>11.2</td>\n",
              "      <td>6</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4006</th>\n",
              "      <td>7.6</td>\n",
              "      <td>0.310</td>\n",
              "      <td>0.27</td>\n",
              "      <td>5.80</td>\n",
              "      <td>0.036</td>\n",
              "      <td>23.0</td>\n",
              "      <td>109.0</td>\n",
              "      <td>0.99399</td>\n",
              "      <td>3.34</td>\n",
              "      <td>0.54</td>\n",
              "      <td>11.0</td>\n",
              "      <td>6</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6401</th>\n",
              "      <td>5.8</td>\n",
              "      <td>0.280</td>\n",
              "      <td>0.34</td>\n",
              "      <td>2.20</td>\n",
              "      <td>0.037</td>\n",
              "      <td>24.0</td>\n",
              "      <td>125.0</td>\n",
              "      <td>0.98986</td>\n",
              "      <td>3.36</td>\n",
              "      <td>0.33</td>\n",
              "      <td>12.8</td>\n",
              "      <td>8</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>6497 rows × 13 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-207b778d-efa5-4da6-b330-7df37a6be0fa')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-207b778d-efa5-4da6-b330-7df37a6be0fa button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-207b778d-efa5-4da6-b330-7df37a6be0fa');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# df.values\n",
        "# np.asarray(df)\n",
        "# df.to_numpy()\n",
        "dataset = df.values\n",
        "X = dataset[:,:12]\n",
        "Y = dataset[:,12]"
      ],
      "metadata": {
        "id": "0nqTubaGm-rY"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 모델설정\n",
        "model = Sequential()\n",
        "model.add(Dense(30,input_dim=12,activation='relu'))\n",
        "model.add(Dense(12, activation='relu'))\n",
        "model.add(Dense(8, activation='relu'))\n",
        "model.add(Dense(1, activation='sigmoid'))"
      ],
      "metadata": {
        "id": "Qi9svM6Pocvg"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 모델 컴파일\n",
        "model.compile(loss = 'binary_crossentropy',optimizer='adam',metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "KI1ySCyco4nx"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 모델 실행\n",
        "model.fit(X,Y,epochs=200, batch_size=200)"
      ],
      "metadata": {
        "id": "Q0lIYor2pNsn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_dir = '/content/checkpoint/'\n",
        "import os\n",
        "if not os.path.exists(model_dir):\n",
        "  os.mkdir(model_dir)"
      ],
      "metadata": {
        "id": "A7GPfloApVPw"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "checkpointer = ModelCheckpoint(model_dir,monitor='val_loss', vervose=2,save_best_only=True)\n",
        "model = Sequential()\n",
        "model.add(Dense(30,input_dim=12,activation='relu'))\n",
        "model.add(Dense(12, activation='relu'))\n",
        "model.add(Dense(8, activation='relu'))\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "model.compile(loss = 'binary_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
        "model.fit(X,Y,validation_split=0.2, epochs=200, batch_size=200, verbose=0,callbacks=[checkpointer])"
      ],
      "metadata": {
        "id": "le9L9mnVqAfR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 모델설정\n",
        "model = Sequential()\n",
        "model.add(Dense(30,input_dim=12,activation='relu'))\n",
        "model.add(Dense(12, activation='relu'))\n",
        "model.add(Dense(8, activation='relu'))\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "# 모델 컴파일\n",
        "model.compile(loss = 'binary_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
        "# 모델 실행\n",
        "history =  model.fit(X,Y, validation_split=0.33 , epochs=3500, batch_size=500)\n",
        "y_vloss =  history.history['val_loss']  # 테스트셋으로 실험결과의 오차값을 지정\n",
        "y_acc = history.history['accuracy']  # 학습셋으로 측정한 정확도\n",
        "\n"
      ],
      "metadata": {
        "id": "hCPAxGAlqoSg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_len = np.arange(len(y_acc))\n",
        "\n",
        "plt.plot(x_len, y_vloss, \"o\", c=\"red\", markersize=3)\n",
        "plt.plot(x_len, y_acc, \"o\", c=\"blue\", markersize=3)\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "id": "M-PWCSB7sLzh",
        "outputId": "f43ed564-746b-493d-8c7d-eaa88ce6a48e"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 조기종료\n",
        "eary_stopping_callback = EarlyStopping(monitor='val_loss', patience=100)\n",
        "# 모델설정\n",
        "model = Sequential()\n",
        "model.add(Dense(30,input_dim=12,activation='relu'))\n",
        "model.add(Dense(12, activation='relu'))\n",
        "model.add(Dense(8, activation='relu'))\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "# 모델 컴파일\n",
        "model.compile(loss = 'binary_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
        "# 모델 실행\n",
        "history =  model.fit(X,Y, validation_split=0.33 , epochs=3500, batch_size=500, callbacks=[eary_stopping_callback])\n",
        "y_vloss =  history.history['val_loss']  # 테스트셋으로 실험결과의 오차값을 지정\n",
        "y_acc = history.history['accuracy']  # 학습셋으로 측정한 정확도\n",
        "x_len = np.arange(len(y_acc))\n",
        "\n",
        "plt.plot(x_len, y_vloss, \"o\", c=\"red\", markersize=3)\n",
        "plt.plot(x_len, y_acc, \"o\", c=\"blue\", markersize=3)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "86JMoufJt7tR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_dir = '/content/checkpoint2/'\n",
        "if not os.path.exists(model_dir):\n",
        "  os.mkdir(model_dir)\n",
        "\n",
        "modelpath =   model_dir+'{epoch:02d}-{val_loss:.4f}.hdf5'\n",
        "\n",
        "# 모델 업데이트 및 저장\n",
        "checkpointer =  ModelCheckpoint(filepath=modelpath, monitor='val_loss', verbose=1, save_best_only=True)\n",
        "# 학습자동중단\n",
        "eary_stopping_callback = EarlyStopping(monitor='val_loss',patience=100)\n",
        "\n",
        "history =  model.fit(X,Y, validation_split=0.33 , epochs=3500, batch_size=500, verbose=1,\n",
        "                     callbacks=[eary_stopping_callback,checkpointer])\n",
        "y_vloss =  history.history['val_loss']  # 테스트셋으로 실험결과의 오차값을 지정\n",
        "y_acc = history.history['accuracy']  # 학습셋으로 측정한 정확도\n",
        "x_len = np.arange(len(y_acc))\n",
        "\n",
        "plt.plot(x_len, y_vloss, \"o\", c=\"red\", markersize=3)\n",
        "plt.plot(x_len, y_acc, \"o\", c=\"blue\", markersize=3)\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "DxdMw6hXusUI",
        "outputId": "23e0f3ea-3d2b-423e-b2e2-801b8c0fd065"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/3500\n",
            "1/9 [==>...........................] - ETA: 0s - loss: 0.0192 - accuracy: 0.9960\n",
            "Epoch 1: val_loss improved from inf to 0.07096, saving model to /content/checkpoint2/01-0.0710.hdf5\n",
            "9/9 [==============================] - 0s 14ms/step - loss: 0.0339 - accuracy: 0.9897 - val_loss: 0.0710 - val_accuracy: 0.9837\n",
            "Epoch 2/3500\n",
            "1/9 [==>...........................] - ETA: 0s - loss: 0.0246 - accuracy: 0.9960\n",
            "Epoch 2: val_loss improved from 0.07096 to 0.06346, saving model to /content/checkpoint2/02-0.0635.hdf5\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 0.0368 - accuracy: 0.9887 - val_loss: 0.0635 - val_accuracy: 0.9874\n",
            "Epoch 3/3500\n",
            "1/9 [==>...........................] - ETA: 0s - loss: 0.0289 - accuracy: 0.9880\n",
            "Epoch 3: val_loss did not improve from 0.06346\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.0370 - accuracy: 0.9876 - val_loss: 0.0643 - val_accuracy: 0.9841\n",
            "Epoch 4/3500\n",
            "1/9 [==>...........................] - ETA: 0s - loss: 0.0683 - accuracy: 0.9860\n",
            "Epoch 4: val_loss did not improve from 0.06346\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.0371 - accuracy: 0.9885 - val_loss: 0.0662 - val_accuracy: 0.9832\n",
            "Epoch 5/3500\n",
            "1/9 [==>...........................] - ETA: 0s - loss: 0.0366 - accuracy: 0.9840\n",
            "Epoch 5: val_loss improved from 0.06346 to 0.06239, saving model to /content/checkpoint2/05-0.0624.hdf5\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.0360 - accuracy: 0.9881 - val_loss: 0.0624 - val_accuracy: 0.9879\n",
            "Epoch 6/3500\n",
            "1/9 [==>...........................] - ETA: 0s - loss: 0.0325 - accuracy: 0.9880\n",
            "Epoch 6: val_loss did not improve from 0.06239\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.0341 - accuracy: 0.9892 - val_loss: 0.0631 - val_accuracy: 0.9879\n",
            "Epoch 7/3500\n",
            "1/9 [==>...........................] - ETA: 0s - loss: 0.0261 - accuracy: 0.9900\n",
            "Epoch 7: val_loss did not improve from 0.06239\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 0.0337 - accuracy: 0.9894 - val_loss: 0.0625 - val_accuracy: 0.9869\n",
            "Epoch 8/3500\n",
            "1/9 [==>...........................] - ETA: 0s - loss: 0.0268 - accuracy: 0.9880\n",
            "Epoch 8: val_loss did not improve from 0.06239\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 0.0340 - accuracy: 0.9892 - val_loss: 0.0649 - val_accuracy: 0.9860\n",
            "Epoch 9/3500\n",
            "1/9 [==>...........................] - ETA: 0s - loss: 0.0257 - accuracy: 0.9900\n",
            "Epoch 9: val_loss did not improve from 0.06239\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.0341 - accuracy: 0.9892 - val_loss: 0.0627 - val_accuracy: 0.9865\n",
            "Epoch 10/3500\n",
            "1/9 [==>...........................] - ETA: 0s - loss: 0.0322 - accuracy: 0.9900\n",
            "Epoch 10: val_loss did not improve from 0.06239\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 0.0347 - accuracy: 0.9897 - val_loss: 0.0630 - val_accuracy: 0.9855\n",
            "Epoch 11/3500\n",
            "1/9 [==>...........................] - ETA: 0s - loss: 0.0299 - accuracy: 0.9900\n",
            "Epoch 11: val_loss did not improve from 0.06239\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 0.0358 - accuracy: 0.9878 - val_loss: 0.0633 - val_accuracy: 0.9855\n",
            "Epoch 12/3500\n",
            "1/9 [==>...........................] - ETA: 0s - loss: 0.0465 - accuracy: 0.9880\n",
            "Epoch 12: val_loss did not improve from 0.06239\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 0.0361 - accuracy: 0.9890 - val_loss: 0.0657 - val_accuracy: 0.9855\n",
            "Epoch 13/3500\n",
            "1/9 [==>...........................] - ETA: 0s - loss: 0.0258 - accuracy: 0.9920\n",
            "Epoch 13: val_loss did not improve from 0.06239\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 0.0390 - accuracy: 0.9871 - val_loss: 0.0692 - val_accuracy: 0.9828\n",
            "Epoch 14/3500\n",
            "1/9 [==>...........................] - ETA: 0s - loss: 0.0352 - accuracy: 0.9920\n",
            "Epoch 14: val_loss did not improve from 0.06239\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.0386 - accuracy: 0.9883 - val_loss: 0.0696 - val_accuracy: 0.9837\n",
            "Epoch 15/3500\n",
            "1/9 [==>...........................] - ETA: 0s - loss: 0.0229 - accuracy: 0.9980\n",
            "Epoch 15: val_loss did not improve from 0.06239\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 0.0371 - accuracy: 0.9885 - val_loss: 0.0726 - val_accuracy: 0.9828\n",
            "Epoch 16/3500\n",
            "1/9 [==>...........................] - ETA: 0s - loss: 0.0368 - accuracy: 0.9860\n",
            "Epoch 16: val_loss did not improve from 0.06239\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 0.0361 - accuracy: 0.9874 - val_loss: 0.0685 - val_accuracy: 0.9841\n",
            "Epoch 17/3500\n",
            "1/9 [==>...........................] - ETA: 0s - loss: 0.0556 - accuracy: 0.9880\n",
            "Epoch 17: val_loss improved from 0.06239 to 0.06225, saving model to /content/checkpoint2/17-0.0622.hdf5\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 0.0388 - accuracy: 0.9871 - val_loss: 0.0622 - val_accuracy: 0.9860\n",
            "Epoch 18/3500\n",
            "1/9 [==>...........................] - ETA: 0s - loss: 0.0296 - accuracy: 0.9880\n",
            "Epoch 18: val_loss did not improve from 0.06225\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.0412 - accuracy: 0.9871 - val_loss: 0.0680 - val_accuracy: 0.9823\n",
            "Epoch 19/3500\n",
            "1/9 [==>...........................] - ETA: 0s - loss: 0.0171 - accuracy: 0.9940\n",
            "Epoch 19: val_loss did not improve from 0.06225\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.0378 - accuracy: 0.9885 - val_loss: 0.0628 - val_accuracy: 0.9855\n",
            "Epoch 20/3500\n",
            "1/9 [==>...........................] - ETA: 0s - loss: 0.0290 - accuracy: 0.9900\n",
            "Epoch 20: val_loss improved from 0.06225 to 0.06209, saving model to /content/checkpoint2/20-0.0621.hdf5\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 0.0405 - accuracy: 0.9869 - val_loss: 0.0621 - val_accuracy: 0.9855\n",
            "Epoch 21/3500\n",
            "1/9 [==>...........................] - ETA: 0s - loss: 0.0325 - accuracy: 0.9860\n",
            "Epoch 21: val_loss did not improve from 0.06209\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.0391 - accuracy: 0.9864 - val_loss: 0.0658 - val_accuracy: 0.9846\n",
            "Epoch 22/3500\n",
            "1/9 [==>...........................] - ETA: 0s - loss: 0.0253 - accuracy: 0.9920\n",
            "Epoch 22: val_loss did not improve from 0.06209\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.0417 - accuracy: 0.9869 - val_loss: 0.0751 - val_accuracy: 0.9828\n",
            "Epoch 23/3500\n",
            "1/9 [==>...........................] - ETA: 0s - loss: 0.0469 - accuracy: 0.9880\n",
            "Epoch 23: val_loss did not improve from 0.06209\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 0.0427 - accuracy: 0.9881 - val_loss: 0.0827 - val_accuracy: 0.9795\n",
            "Epoch 24/3500\n",
            "1/9 [==>...........................] - ETA: 0s - loss: 0.0292 - accuracy: 0.9920\n",
            "Epoch 24: val_loss did not improve from 0.06209\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.0382 - accuracy: 0.9871 - val_loss: 0.0785 - val_accuracy: 0.9818\n",
            "Epoch 25/3500\n",
            "1/9 [==>...........................] - ETA: 0s - loss: 0.0620 - accuracy: 0.9780\n",
            "Epoch 25: val_loss did not improve from 0.06209\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.0409 - accuracy: 0.9867 - val_loss: 0.0682 - val_accuracy: 0.9837\n",
            "Epoch 26/3500\n",
            "1/9 [==>...........................] - ETA: 0s - loss: 0.0607 - accuracy: 0.9820\n",
            "Epoch 26: val_loss did not improve from 0.06209\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 0.0389 - accuracy: 0.9874 - val_loss: 0.0665 - val_accuracy: 0.9855\n",
            "Epoch 27/3500\n",
            "1/9 [==>...........................] - ETA: 0s - loss: 0.0305 - accuracy: 0.9880\n",
            "Epoch 27: val_loss did not improve from 0.06209\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.0392 - accuracy: 0.9869 - val_loss: 0.0650 - val_accuracy: 0.9869\n",
            "Epoch 28/3500\n",
            "1/9 [==>...........................] - ETA: 0s - loss: 0.0297 - accuracy: 0.9900\n",
            "Epoch 28: val_loss did not improve from 0.06209\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.0344 - accuracy: 0.9876 - val_loss: 0.0624 - val_accuracy: 0.9874\n",
            "Epoch 29/3500\n",
            "1/9 [==>...........................] - ETA: 0s - loss: 0.0339 - accuracy: 0.9880\n",
            "Epoch 29: val_loss did not improve from 0.06209\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.0333 - accuracy: 0.9885 - val_loss: 0.0630 - val_accuracy: 0.9879\n",
            "Epoch 30/3500\n",
            "1/9 [==>...........................] - ETA: 0s - loss: 0.0498 - accuracy: 0.9860\n",
            "Epoch 30: val_loss did not improve from 0.06209\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.0360 - accuracy: 0.9887 - val_loss: 0.0740 - val_accuracy: 0.9823\n",
            "Epoch 31/3500\n",
            "1/9 [==>...........................] - ETA: 0s - loss: 0.0248 - accuracy: 0.9920\n",
            "Epoch 31: val_loss did not improve from 0.06209\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 0.0361 - accuracy: 0.9881 - val_loss: 0.0710 - val_accuracy: 0.9837\n",
            "Epoch 32/3500\n",
            "1/9 [==>...........................] - ETA: 0s - loss: 0.0335 - accuracy: 0.9880\n",
            "Epoch 32: val_loss did not improve from 0.06209\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.0354 - accuracy: 0.9887 - val_loss: 0.0658 - val_accuracy: 0.9860\n",
            "Epoch 33/3500\n",
            "1/9 [==>...........................] - ETA: 0s - loss: 0.0219 - accuracy: 0.9900\n",
            "Epoch 33: val_loss did not improve from 0.06209\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.0367 - accuracy: 0.9871 - val_loss: 0.0672 - val_accuracy: 0.9860\n",
            "Epoch 34/3500\n",
            "1/9 [==>...........................] - ETA: 0s - loss: 0.0248 - accuracy: 0.9900\n",
            "Epoch 34: val_loss did not improve from 0.06209\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.0345 - accuracy: 0.9887 - val_loss: 0.0838 - val_accuracy: 0.9804\n",
            "Epoch 35/3500\n",
            "1/9 [==>...........................] - ETA: 0s - loss: 0.0462 - accuracy: 0.9860\n",
            "Epoch 35: val_loss did not improve from 0.06209\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.0396 - accuracy: 0.9876 - val_loss: 0.0770 - val_accuracy: 0.9823\n",
            "Epoch 36/3500\n",
            "1/9 [==>...........................] - ETA: 0s - loss: 0.0327 - accuracy: 0.9900\n",
            "Epoch 36: val_loss did not improve from 0.06209\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 0.0382 - accuracy: 0.9871 - val_loss: 0.0673 - val_accuracy: 0.9841\n",
            "Epoch 37/3500\n",
            "1/9 [==>...........................] - ETA: 0s - loss: 0.0451 - accuracy: 0.9820\n",
            "Epoch 37: val_loss did not improve from 0.06209\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.0373 - accuracy: 0.9876 - val_loss: 0.0701 - val_accuracy: 0.9823\n",
            "Epoch 38/3500\n",
            "1/9 [==>...........................] - ETA: 0s - loss: 0.0562 - accuracy: 0.9840\n",
            "Epoch 38: val_loss did not improve from 0.06209\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 0.0384 - accuracy: 0.9876 - val_loss: 0.0630 - val_accuracy: 0.9869\n",
            "Epoch 39/3500\n",
            "1/9 [==>...........................] - ETA: 0s - loss: 0.0271 - accuracy: 0.9900\n",
            "Epoch 39: val_loss did not improve from 0.06209\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.0393 - accuracy: 0.9876 - val_loss: 0.0655 - val_accuracy: 0.9846\n",
            "Epoch 40/3500\n",
            "1/9 [==>...........................] - ETA: 0s - loss: 0.0206 - accuracy: 0.9940\n",
            "Epoch 40: val_loss did not improve from 0.06209\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.0414 - accuracy: 0.9858 - val_loss: 0.0627 - val_accuracy: 0.9846\n",
            "Epoch 41/3500\n",
            "1/9 [==>...........................] - ETA: 0s - loss: 0.0369 - accuracy: 0.9880\n",
            "Epoch 41: val_loss improved from 0.06209 to 0.06193, saving model to /content/checkpoint2/41-0.0619.hdf5\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 0.0354 - accuracy: 0.9892 - val_loss: 0.0619 - val_accuracy: 0.9874\n",
            "Epoch 42/3500\n",
            "1/9 [==>...........................] - ETA: 0s - loss: 0.0252 - accuracy: 0.9920\n",
            "Epoch 42: val_loss did not improve from 0.06193\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.0347 - accuracy: 0.9897 - val_loss: 0.0656 - val_accuracy: 0.9869\n",
            "Epoch 43/3500\n",
            "1/9 [==>...........................] - ETA: 0s - loss: 0.0323 - accuracy: 0.9860\n",
            "Epoch 43: val_loss did not improve from 0.06193\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 0.0368 - accuracy: 0.9869 - val_loss: 0.0646 - val_accuracy: 0.9851\n",
            "Epoch 44/3500\n",
            "1/9 [==>...........................] - ETA: 0s - loss: 0.0297 - accuracy: 0.9900\n",
            "Epoch 44: val_loss did not improve from 0.06193\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.0365 - accuracy: 0.9885 - val_loss: 0.0625 - val_accuracy: 0.9860\n",
            "Epoch 45/3500\n",
            "1/9 [==>...........................] - ETA: 0s - loss: 0.0444 - accuracy: 0.9920\n",
            "Epoch 45: val_loss did not improve from 0.06193\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 0.0360 - accuracy: 0.9883 - val_loss: 0.0644 - val_accuracy: 0.9837\n",
            "Epoch 46/3500\n",
            "1/9 [==>...........................] - ETA: 0s - loss: 0.0461 - accuracy: 0.9840\n",
            "Epoch 46: val_loss did not improve from 0.06193\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.0340 - accuracy: 0.9894 - val_loss: 0.0632 - val_accuracy: 0.9879\n",
            "Epoch 47/3500\n",
            "1/9 [==>...........................] - ETA: 0s - loss: 0.0512 - accuracy: 0.9800\n",
            "Epoch 47: val_loss did not improve from 0.06193\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.0331 - accuracy: 0.9887 - val_loss: 0.0630 - val_accuracy: 0.9874\n",
            "Epoch 48/3500\n",
            "1/9 [==>...........................] - ETA: 0s - loss: 0.0384 - accuracy: 0.9860\n",
            "Epoch 48: val_loss did not improve from 0.06193\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 0.0338 - accuracy: 0.9887 - val_loss: 0.0654 - val_accuracy: 0.9860\n",
            "Epoch 49/3500\n",
            "1/9 [==>...........................] - ETA: 0s - loss: 0.0296 - accuracy: 0.9900\n",
            "Epoch 49: val_loss did not improve from 0.06193\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 0.0339 - accuracy: 0.9883 - val_loss: 0.0644 - val_accuracy: 0.9874\n",
            "Epoch 50/3500\n",
            "1/9 [==>...........................] - ETA: 0s - loss: 0.0561 - accuracy: 0.9800\n",
            "Epoch 50: val_loss did not improve from 0.06193\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 0.0338 - accuracy: 0.9894 - val_loss: 0.0629 - val_accuracy: 0.9865\n",
            "Epoch 51/3500\n",
            "1/9 [==>...........................] - ETA: 0s - loss: 0.0615 - accuracy: 0.9800\n",
            "Epoch 51: val_loss did not improve from 0.06193\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.0341 - accuracy: 0.9885 - val_loss: 0.0633 - val_accuracy: 0.9865\n",
            "Epoch 52/3500\n",
            "1/9 [==>...........................] - ETA: 0s - loss: 0.0313 - accuracy: 0.9880\n",
            "Epoch 52: val_loss did not improve from 0.06193\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 0.0340 - accuracy: 0.9894 - val_loss: 0.0655 - val_accuracy: 0.9865\n",
            "Epoch 53/3500\n",
            "1/9 [==>...........................] - ETA: 0s - loss: 0.0335 - accuracy: 0.9840\n",
            "Epoch 53: val_loss did not improve from 0.06193\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.0331 - accuracy: 0.9887 - val_loss: 0.0652 - val_accuracy: 0.9855\n",
            "Epoch 54/3500\n",
            "1/9 [==>...........................] - ETA: 0s - loss: 0.0314 - accuracy: 0.9900\n",
            "Epoch 54: val_loss did not improve from 0.06193\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 0.0333 - accuracy: 0.9894 - val_loss: 0.0639 - val_accuracy: 0.9874\n",
            "Epoch 55/3500\n",
            "1/9 [==>...........................] - ETA: 0s - loss: 0.0201 - accuracy: 0.9900\n",
            "Epoch 55: val_loss did not improve from 0.06193\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 0.0351 - accuracy: 0.9885 - val_loss: 0.0650 - val_accuracy: 0.9865\n",
            "Epoch 56/3500\n",
            "1/9 [==>...........................] - ETA: 0s - loss: 0.0299 - accuracy: 0.9900\n",
            "Epoch 56: val_loss did not improve from 0.06193\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.0352 - accuracy: 0.9890 - val_loss: 0.0632 - val_accuracy: 0.9860\n",
            "Epoch 57/3500\n",
            "1/9 [==>...........................] - ETA: 0s - loss: 0.0311 - accuracy: 0.9900\n",
            "Epoch 57: val_loss did not improve from 0.06193\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.0368 - accuracy: 0.9894 - val_loss: 0.0621 - val_accuracy: 0.9869\n",
            "Epoch 58/3500\n",
            "1/9 [==>...........................] - ETA: 0s - loss: 0.0301 - accuracy: 0.9880\n",
            "Epoch 58: val_loss did not improve from 0.06193\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.0335 - accuracy: 0.9892 - val_loss: 0.0631 - val_accuracy: 0.9865\n",
            "Epoch 59/3500\n",
            "1/9 [==>...........................] - ETA: 0s - loss: 0.0179 - accuracy: 0.9940\n",
            "Epoch 59: val_loss improved from 0.06193 to 0.06166, saving model to /content/checkpoint2/59-0.0617.hdf5\n",
            "9/9 [==============================] - 0s 11ms/step - loss: 0.0343 - accuracy: 0.9892 - val_loss: 0.0617 - val_accuracy: 0.9865\n",
            "Epoch 60/3500\n",
            "1/9 [==>...........................] - ETA: 0s - loss: 0.0491 - accuracy: 0.9840\n",
            "Epoch 60: val_loss did not improve from 0.06166\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 0.0334 - accuracy: 0.9890 - val_loss: 0.0650 - val_accuracy: 0.9865\n",
            "Epoch 61/3500\n",
            "1/9 [==>...........................] - ETA: 0s - loss: 0.0376 - accuracy: 0.9920\n",
            "Epoch 61: val_loss did not improve from 0.06166\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.0331 - accuracy: 0.9897 - val_loss: 0.0659 - val_accuracy: 0.9860\n",
            "Epoch 62/3500\n",
            "1/9 [==>...........................] - ETA: 0s - loss: 0.0508 - accuracy: 0.9840\n",
            "Epoch 62: val_loss did not improve from 0.06166\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.0331 - accuracy: 0.9897 - val_loss: 0.0635 - val_accuracy: 0.9874\n",
            "Epoch 63/3500\n",
            "1/9 [==>...........................] - ETA: 0s - loss: 0.0382 - accuracy: 0.9900\n",
            "Epoch 63: val_loss did not improve from 0.06166\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.0335 - accuracy: 0.9885 - val_loss: 0.0627 - val_accuracy: 0.9869\n",
            "Epoch 64/3500\n",
            "1/9 [==>...........................] - ETA: 0s - loss: 0.0489 - accuracy: 0.9840\n",
            "Epoch 64: val_loss did not improve from 0.06166\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 0.0330 - accuracy: 0.9892 - val_loss: 0.0679 - val_accuracy: 0.9851\n",
            "Epoch 65/3500\n",
            "1/9 [==>...........................] - ETA: 0s - loss: 0.0268 - accuracy: 0.9900\n",
            "Epoch 65: val_loss did not improve from 0.06166\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.0326 - accuracy: 0.9899 - val_loss: 0.0629 - val_accuracy: 0.9874\n",
            "Epoch 66/3500\n",
            "1/9 [==>...........................] - ETA: 0s - loss: 0.0259 - accuracy: 0.9940\n",
            "Epoch 66: val_loss did not improve from 0.06166\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.0336 - accuracy: 0.9894 - val_loss: 0.0641 - val_accuracy: 0.9874\n",
            "Epoch 67/3500\n",
            "1/9 [==>...........................] - ETA: 0s - loss: 0.0179 - accuracy: 0.9900\n",
            "Epoch 67: val_loss did not improve from 0.06166\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.0332 - accuracy: 0.9892 - val_loss: 0.0643 - val_accuracy: 0.9841\n",
            "Epoch 68/3500\n",
            "1/9 [==>...........................] - ETA: 0s - loss: 0.0577 - accuracy: 0.9860\n",
            "Epoch 68: val_loss did not improve from 0.06166\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.0336 - accuracy: 0.9892 - val_loss: 0.0628 - val_accuracy: 0.9869\n",
            "Epoch 69/3500\n",
            "1/9 [==>...........................] - ETA: 0s - loss: 0.0380 - accuracy: 0.9940\n",
            "Epoch 69: val_loss did not improve from 0.06166\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.0332 - accuracy: 0.9899 - val_loss: 0.0649 - val_accuracy: 0.9869\n",
            "Epoch 70/3500\n",
            "1/9 [==>...........................] - ETA: 0s - loss: 0.0308 - accuracy: 0.9840\n",
            "Epoch 70: val_loss did not improve from 0.06166\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.0336 - accuracy: 0.9887 - val_loss: 0.0634 - val_accuracy: 0.9855\n",
            "Epoch 71/3500\n",
            "1/9 [==>...........................] - ETA: 0s - loss: 0.0462 - accuracy: 0.9860\n",
            "Epoch 71: val_loss did not improve from 0.06166\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.0374 - accuracy: 0.9874 - val_loss: 0.0760 - val_accuracy: 0.9786\n",
            "Epoch 72/3500\n",
            "1/9 [==>...........................] - ETA: 0s - loss: 0.0666 - accuracy: 0.9760\n",
            "Epoch 72: val_loss did not improve from 0.06166\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.0432 - accuracy: 0.9848 - val_loss: 0.0692 - val_accuracy: 0.9828\n",
            "Epoch 73/3500\n",
            "1/9 [==>...........................] - ETA: 0s - loss: 0.0791 - accuracy: 0.9780\n",
            "Epoch 73: val_loss did not improve from 0.06166\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.0417 - accuracy: 0.9855 - val_loss: 0.0627 - val_accuracy: 0.9883\n",
            "Epoch 74/3500\n",
            "1/9 [==>...........................] - ETA: 0s - loss: 0.0205 - accuracy: 0.9900\n",
            "Epoch 74: val_loss did not improve from 0.06166\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.0383 - accuracy: 0.9853 - val_loss: 0.0691 - val_accuracy: 0.9832\n",
            "Epoch 75/3500\n",
            "1/9 [==>...........................] - ETA: 0s - loss: 0.0378 - accuracy: 0.9860\n",
            "Epoch 75: val_loss did not improve from 0.06166\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.0356 - accuracy: 0.9876 - val_loss: 0.0681 - val_accuracy: 0.9832\n",
            "Epoch 76/3500\n",
            "1/9 [==>...........................] - ETA: 0s - loss: 0.0412 - accuracy: 0.9840\n",
            "Epoch 76: val_loss did not improve from 0.06166\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.0349 - accuracy: 0.9883 - val_loss: 0.0674 - val_accuracy: 0.9860\n",
            "Epoch 77/3500\n",
            "1/9 [==>...........................] - ETA: 0s - loss: 0.0284 - accuracy: 0.9900\n",
            "Epoch 77: val_loss did not improve from 0.06166\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 0.0385 - accuracy: 0.9881 - val_loss: 0.0682 - val_accuracy: 0.9823\n",
            "Epoch 78/3500\n",
            "1/9 [==>...........................] - ETA: 0s - loss: 0.0276 - accuracy: 0.9860\n",
            "Epoch 78: val_loss did not improve from 0.06166\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.0386 - accuracy: 0.9871 - val_loss: 0.0642 - val_accuracy: 0.9837\n",
            "Epoch 79/3500\n",
            "1/9 [==>...........................] - ETA: 0s - loss: 0.0324 - accuracy: 0.9900\n",
            "Epoch 79: val_loss did not improve from 0.06166\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.0348 - accuracy: 0.9885 - val_loss: 0.0620 - val_accuracy: 0.9860\n",
            "Epoch 80/3500\n",
            "1/9 [==>...........................] - ETA: 0s - loss: 0.0410 - accuracy: 0.9860\n",
            "Epoch 80: val_loss did not improve from 0.06166\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 0.0341 - accuracy: 0.9894 - val_loss: 0.0642 - val_accuracy: 0.9865\n",
            "Epoch 81/3500\n",
            "1/9 [==>...........................] - ETA: 0s - loss: 0.0459 - accuracy: 0.9840\n",
            "Epoch 81: val_loss did not improve from 0.06166\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 0.0340 - accuracy: 0.9890 - val_loss: 0.0665 - val_accuracy: 0.9846\n",
            "Epoch 82/3500\n",
            "1/9 [==>...........................] - ETA: 0s - loss: 0.0523 - accuracy: 0.9860\n",
            "Epoch 82: val_loss did not improve from 0.06166\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.0348 - accuracy: 0.9897 - val_loss: 0.0644 - val_accuracy: 0.9855\n",
            "Epoch 83/3500\n",
            "1/9 [==>...........................] - ETA: 0s - loss: 0.0215 - accuracy: 0.9900\n",
            "Epoch 83: val_loss did not improve from 0.06166\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 0.0354 - accuracy: 0.9887 - val_loss: 0.0646 - val_accuracy: 0.9841\n",
            "Epoch 84/3500\n",
            "1/9 [==>...........................] - ETA: 0s - loss: 0.0317 - accuracy: 0.9860\n",
            "Epoch 84: val_loss did not improve from 0.06166\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 0.0336 - accuracy: 0.9897 - val_loss: 0.0657 - val_accuracy: 0.9865\n",
            "Epoch 85/3500\n",
            "1/9 [==>...........................] - ETA: 0s - loss: 0.0277 - accuracy: 0.9860\n",
            "Epoch 85: val_loss did not improve from 0.06166\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 0.0343 - accuracy: 0.9885 - val_loss: 0.0636 - val_accuracy: 0.9851\n",
            "Epoch 86/3500\n",
            "1/9 [==>...........................] - ETA: 0s - loss: 0.0556 - accuracy: 0.9800\n",
            "Epoch 86: val_loss did not improve from 0.06166\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.0341 - accuracy: 0.9890 - val_loss: 0.0621 - val_accuracy: 0.9869\n",
            "Epoch 87/3500\n",
            "1/9 [==>...........................] - ETA: 0s - loss: 0.0219 - accuracy: 0.9920\n",
            "Epoch 87: val_loss did not improve from 0.06166\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.0332 - accuracy: 0.9894 - val_loss: 0.0632 - val_accuracy: 0.9851\n",
            "Epoch 88/3500\n",
            "1/9 [==>...........................] - ETA: 0s - loss: 0.0453 - accuracy: 0.9820\n",
            "Epoch 88: val_loss did not improve from 0.06166\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.0323 - accuracy: 0.9894 - val_loss: 0.0645 - val_accuracy: 0.9869\n",
            "Epoch 89/3500\n",
            "1/9 [==>...........................] - ETA: 0s - loss: 0.0533 - accuracy: 0.9800\n",
            "Epoch 89: val_loss did not improve from 0.06166\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.0369 - accuracy: 0.9878 - val_loss: 0.0628 - val_accuracy: 0.9855\n",
            "Epoch 90/3500\n",
            "1/9 [==>...........................] - ETA: 0s - loss: 0.0280 - accuracy: 0.9900\n",
            "Epoch 90: val_loss did not improve from 0.06166\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.0361 - accuracy: 0.9871 - val_loss: 0.0627 - val_accuracy: 0.9855\n",
            "Epoch 91/3500\n",
            "1/9 [==>...........................] - ETA: 0s - loss: 0.0345 - accuracy: 0.9860\n",
            "Epoch 91: val_loss did not improve from 0.06166\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.0337 - accuracy: 0.9894 - val_loss: 0.0631 - val_accuracy: 0.9869\n",
            "Epoch 92/3500\n",
            "1/9 [==>...........................] - ETA: 0s - loss: 0.0507 - accuracy: 0.9860\n",
            "Epoch 92: val_loss did not improve from 0.06166\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.0342 - accuracy: 0.9881 - val_loss: 0.0704 - val_accuracy: 0.9851\n",
            "Epoch 93/3500\n",
            "1/9 [==>...........................] - ETA: 0s - loss: 0.0443 - accuracy: 0.9860\n",
            "Epoch 93: val_loss did not improve from 0.06166\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 0.0345 - accuracy: 0.9892 - val_loss: 0.0649 - val_accuracy: 0.9869\n",
            "Epoch 94/3500\n",
            "1/9 [==>...........................] - ETA: 0s - loss: 0.0412 - accuracy: 0.9840\n",
            "Epoch 94: val_loss did not improve from 0.06166\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.0333 - accuracy: 0.9892 - val_loss: 0.0695 - val_accuracy: 0.9860\n",
            "Epoch 95/3500\n",
            "1/9 [==>...........................] - ETA: 0s - loss: 0.0584 - accuracy: 0.9840\n",
            "Epoch 95: val_loss did not improve from 0.06166\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 0.0336 - accuracy: 0.9885 - val_loss: 0.0720 - val_accuracy: 0.9828\n",
            "Epoch 96/3500\n",
            "1/9 [==>...........................] - ETA: 0s - loss: 0.0562 - accuracy: 0.9840\n",
            "Epoch 96: val_loss did not improve from 0.06166\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.0351 - accuracy: 0.9899 - val_loss: 0.0661 - val_accuracy: 0.9846\n",
            "Epoch 97/3500\n",
            "1/9 [==>...........................] - ETA: 0s - loss: 0.0258 - accuracy: 0.9920\n",
            "Epoch 97: val_loss did not improve from 0.06166\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 0.0362 - accuracy: 0.9890 - val_loss: 0.0646 - val_accuracy: 0.9860\n",
            "Epoch 98/3500\n",
            "1/9 [==>...........................] - ETA: 0s - loss: 0.0319 - accuracy: 0.9940\n",
            "Epoch 98: val_loss did not improve from 0.06166\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 0.0365 - accuracy: 0.9892 - val_loss: 0.0624 - val_accuracy: 0.9865\n",
            "Epoch 99/3500\n",
            "1/9 [==>...........................] - ETA: 0s - loss: 0.0619 - accuracy: 0.9800\n",
            "Epoch 99: val_loss did not improve from 0.06166\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.0351 - accuracy: 0.9887 - val_loss: 0.0630 - val_accuracy: 0.9869\n",
            "Epoch 100/3500\n",
            "1/9 [==>...........................] - ETA: 0s - loss: 0.0178 - accuracy: 0.9920\n",
            "Epoch 100: val_loss did not improve from 0.06166\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 0.0339 - accuracy: 0.9894 - val_loss: 0.0643 - val_accuracy: 0.9860\n",
            "Epoch 101/3500\n",
            "1/9 [==>...........................] - ETA: 0s - loss: 0.0500 - accuracy: 0.9860\n",
            "Epoch 101: val_loss did not improve from 0.06166\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 0.0323 - accuracy: 0.9899 - val_loss: 0.0636 - val_accuracy: 0.9855\n",
            "Epoch 102/3500\n",
            "1/9 [==>...........................] - ETA: 0s - loss: 0.0378 - accuracy: 0.9940\n",
            "Epoch 102: val_loss did not improve from 0.06166\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.0322 - accuracy: 0.9897 - val_loss: 0.0662 - val_accuracy: 0.9855\n",
            "Epoch 103/3500\n",
            "1/9 [==>...........................] - ETA: 0s - loss: 0.0409 - accuracy: 0.9880\n",
            "Epoch 103: val_loss did not improve from 0.06166\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.0341 - accuracy: 0.9892 - val_loss: 0.0652 - val_accuracy: 0.9860\n",
            "Epoch 104/3500\n",
            "1/9 [==>...........................] - ETA: 0s - loss: 0.0271 - accuracy: 0.9920\n",
            "Epoch 104: val_loss did not improve from 0.06166\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 0.0360 - accuracy: 0.9887 - val_loss: 0.0627 - val_accuracy: 0.9846\n",
            "Epoch 105/3500\n",
            "1/9 [==>...........................] - ETA: 0s - loss: 0.0276 - accuracy: 0.9900\n",
            "Epoch 105: val_loss did not improve from 0.06166\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 0.0360 - accuracy: 0.9867 - val_loss: 0.0673 - val_accuracy: 0.9818\n",
            "Epoch 106/3500\n",
            "1/9 [==>...........................] - ETA: 0s - loss: 0.0293 - accuracy: 0.9880\n",
            "Epoch 106: val_loss did not improve from 0.06166\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 0.0396 - accuracy: 0.9883 - val_loss: 0.0652 - val_accuracy: 0.9841\n",
            "Epoch 107/3500\n",
            "1/9 [==>...........................] - ETA: 0s - loss: 0.0256 - accuracy: 0.9880\n",
            "Epoch 107: val_loss did not improve from 0.06166\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.0340 - accuracy: 0.9887 - val_loss: 0.0650 - val_accuracy: 0.9865\n",
            "Epoch 108/3500\n",
            "1/9 [==>...........................] - ETA: 0s - loss: 0.0138 - accuracy: 0.9960\n",
            "Epoch 108: val_loss did not improve from 0.06166\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.0327 - accuracy: 0.9897 - val_loss: 0.0631 - val_accuracy: 0.9874\n",
            "Epoch 109/3500\n",
            "1/9 [==>...........................] - ETA: 0s - loss: 0.0510 - accuracy: 0.9820\n",
            "Epoch 109: val_loss did not improve from 0.06166\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 0.0327 - accuracy: 0.9897 - val_loss: 0.0634 - val_accuracy: 0.9855\n",
            "Epoch 110/3500\n",
            "1/9 [==>...........................] - ETA: 0s - loss: 0.0312 - accuracy: 0.9900\n",
            "Epoch 110: val_loss did not improve from 0.06166\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 0.0326 - accuracy: 0.9881 - val_loss: 0.0631 - val_accuracy: 0.9860\n",
            "Epoch 111/3500\n",
            "1/9 [==>...........................] - ETA: 0s - loss: 0.0364 - accuracy: 0.9880\n",
            "Epoch 111: val_loss did not improve from 0.06166\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 0.0336 - accuracy: 0.9897 - val_loss: 0.0705 - val_accuracy: 0.9837\n",
            "Epoch 112/3500\n",
            "1/9 [==>...........................] - ETA: 0s - loss: 0.0255 - accuracy: 0.9940\n",
            "Epoch 112: val_loss did not improve from 0.06166\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.0346 - accuracy: 0.9878 - val_loss: 0.0691 - val_accuracy: 0.9832\n",
            "Epoch 113/3500\n",
            "1/9 [==>...........................] - ETA: 0s - loss: 0.0270 - accuracy: 0.9900\n",
            "Epoch 113: val_loss did not improve from 0.06166\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 0.0354 - accuracy: 0.9890 - val_loss: 0.0671 - val_accuracy: 0.9860\n",
            "Epoch 114/3500\n",
            "1/9 [==>...........................] - ETA: 0s - loss: 0.0186 - accuracy: 0.9940\n",
            "Epoch 114: val_loss did not improve from 0.06166\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.0343 - accuracy: 0.9881 - val_loss: 0.0628 - val_accuracy: 0.9860\n",
            "Epoch 115/3500\n",
            "1/9 [==>...........................] - ETA: 0s - loss: 0.0381 - accuracy: 0.9820\n",
            "Epoch 115: val_loss did not improve from 0.06166\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.0356 - accuracy: 0.9885 - val_loss: 0.0672 - val_accuracy: 0.9837\n",
            "Epoch 116/3500\n",
            "1/9 [==>...........................] - ETA: 0s - loss: 0.0349 - accuracy: 0.9900\n",
            "Epoch 116: val_loss did not improve from 0.06166\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.0354 - accuracy: 0.9883 - val_loss: 0.0635 - val_accuracy: 0.9846\n",
            "Epoch 117/3500\n",
            "1/9 [==>...........................] - ETA: 0s - loss: 0.0200 - accuracy: 0.9900\n",
            "Epoch 117: val_loss did not improve from 0.06166\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 0.0341 - accuracy: 0.9890 - val_loss: 0.0644 - val_accuracy: 0.9860\n",
            "Epoch 118/3500\n",
            "1/9 [==>...........................] - ETA: 0s - loss: 0.0292 - accuracy: 0.9900\n",
            "Epoch 118: val_loss did not improve from 0.06166\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 0.0335 - accuracy: 0.9899 - val_loss: 0.0646 - val_accuracy: 0.9865\n",
            "Epoch 119/3500\n",
            "1/9 [==>...........................] - ETA: 0s - loss: 0.0197 - accuracy: 0.9980\n",
            "Epoch 119: val_loss did not improve from 0.06166\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 0.0335 - accuracy: 0.9908 - val_loss: 0.0678 - val_accuracy: 0.9837\n",
            "Epoch 120/3500\n",
            "1/9 [==>...........................] - ETA: 0s - loss: 0.0382 - accuracy: 0.9880\n",
            "Epoch 120: val_loss did not improve from 0.06166\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.0342 - accuracy: 0.9885 - val_loss: 0.0702 - val_accuracy: 0.9855\n",
            "Epoch 121/3500\n",
            "1/9 [==>...........................] - ETA: 0s - loss: 0.0556 - accuracy: 0.9860\n",
            "Epoch 121: val_loss did not improve from 0.06166\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 0.0338 - accuracy: 0.9899 - val_loss: 0.0700 - val_accuracy: 0.9832\n",
            "Epoch 122/3500\n",
            "1/9 [==>...........................] - ETA: 0s - loss: 0.0285 - accuracy: 0.9880\n",
            "Epoch 122: val_loss did not improve from 0.06166\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 0.0329 - accuracy: 0.9890 - val_loss: 0.0631 - val_accuracy: 0.9874\n",
            "Epoch 123/3500\n",
            "1/9 [==>...........................] - ETA: 0s - loss: 0.0526 - accuracy: 0.9820\n",
            "Epoch 123: val_loss did not improve from 0.06166\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.0320 - accuracy: 0.9897 - val_loss: 0.0633 - val_accuracy: 0.9851\n",
            "Epoch 124/3500\n",
            "1/9 [==>...........................] - ETA: 0s - loss: 0.0215 - accuracy: 0.9920\n",
            "Epoch 124: val_loss did not improve from 0.06166\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 0.0321 - accuracy: 0.9897 - val_loss: 0.0638 - val_accuracy: 0.9865\n",
            "Epoch 125/3500\n",
            "1/9 [==>...........................] - ETA: 0s - loss: 0.0440 - accuracy: 0.9880\n",
            "Epoch 125: val_loss did not improve from 0.06166\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.0320 - accuracy: 0.9892 - val_loss: 0.0705 - val_accuracy: 0.9846\n",
            "Epoch 126/3500\n",
            "1/9 [==>...........................] - ETA: 0s - loss: 0.0347 - accuracy: 0.9920\n",
            "Epoch 126: val_loss did not improve from 0.06166\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.0402 - accuracy: 0.9869 - val_loss: 0.0678 - val_accuracy: 0.9832\n",
            "Epoch 127/3500\n",
            "1/9 [==>...........................] - ETA: 0s - loss: 0.0247 - accuracy: 0.9960\n",
            "Epoch 127: val_loss did not improve from 0.06166\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 0.0381 - accuracy: 0.9874 - val_loss: 0.0629 - val_accuracy: 0.9855\n",
            "Epoch 128/3500\n",
            "1/9 [==>...........................] - ETA: 0s - loss: 0.0438 - accuracy: 0.9840\n",
            "Epoch 128: val_loss did not improve from 0.06166\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 0.0335 - accuracy: 0.9874 - val_loss: 0.0635 - val_accuracy: 0.9860\n",
            "Epoch 129/3500\n",
            "1/9 [==>...........................] - ETA: 0s - loss: 0.0209 - accuracy: 0.9880\n",
            "Epoch 129: val_loss did not improve from 0.06166\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 0.0318 - accuracy: 0.9894 - val_loss: 0.0651 - val_accuracy: 0.9860\n",
            "Epoch 130/3500\n",
            "1/9 [==>...........................] - ETA: 0s - loss: 0.0429 - accuracy: 0.9860\n",
            "Epoch 130: val_loss did not improve from 0.06166\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 0.0328 - accuracy: 0.9892 - val_loss: 0.0654 - val_accuracy: 0.9865\n",
            "Epoch 131/3500\n",
            "1/9 [==>...........................] - ETA: 0s - loss: 0.0467 - accuracy: 0.9880\n",
            "Epoch 131: val_loss did not improve from 0.06166\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 0.0320 - accuracy: 0.9901 - val_loss: 0.0641 - val_accuracy: 0.9865\n",
            "Epoch 132/3500\n",
            "1/9 [==>...........................] - ETA: 0s - loss: 0.0164 - accuracy: 0.9960\n",
            "Epoch 132: val_loss did not improve from 0.06166\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.0340 - accuracy: 0.9885 - val_loss: 0.0742 - val_accuracy: 0.9809\n",
            "Epoch 133/3500\n",
            "1/9 [==>...........................] - ETA: 0s - loss: 0.0590 - accuracy: 0.9820\n",
            "Epoch 133: val_loss did not improve from 0.06166\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 0.0379 - accuracy: 0.9885 - val_loss: 0.0788 - val_accuracy: 0.9772\n",
            "Epoch 134/3500\n",
            "1/9 [==>...........................] - ETA: 0s - loss: 0.1008 - accuracy: 0.9700\n",
            "Epoch 134: val_loss did not improve from 0.06166\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.0407 - accuracy: 0.9871 - val_loss: 0.0623 - val_accuracy: 0.9869\n",
            "Epoch 135/3500\n",
            "1/9 [==>...........................] - ETA: 0s - loss: 0.0286 - accuracy: 0.9900\n",
            "Epoch 135: val_loss did not improve from 0.06166\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 0.0328 - accuracy: 0.9903 - val_loss: 0.0639 - val_accuracy: 0.9855\n",
            "Epoch 136/3500\n",
            "1/9 [==>...........................] - ETA: 0s - loss: 0.0396 - accuracy: 0.9840\n",
            "Epoch 136: val_loss did not improve from 0.06166\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 0.0340 - accuracy: 0.9887 - val_loss: 0.0644 - val_accuracy: 0.9865\n",
            "Epoch 137/3500\n",
            "1/9 [==>...........................] - ETA: 0s - loss: 0.0222 - accuracy: 0.9900\n",
            "Epoch 137: val_loss did not improve from 0.06166\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 0.0354 - accuracy: 0.9883 - val_loss: 0.0694 - val_accuracy: 0.9832\n",
            "Epoch 138/3500\n",
            "1/9 [==>...........................] - ETA: 0s - loss: 0.0544 - accuracy: 0.9820\n",
            "Epoch 138: val_loss did not improve from 0.06166\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.0338 - accuracy: 0.9890 - val_loss: 0.0690 - val_accuracy: 0.9851\n",
            "Epoch 139/3500\n",
            "1/9 [==>...........................] - ETA: 0s - loss: 0.0314 - accuracy: 0.9900\n",
            "Epoch 139: val_loss did not improve from 0.06166\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.0340 - accuracy: 0.9903 - val_loss: 0.0689 - val_accuracy: 0.9828\n",
            "Epoch 140/3500\n",
            "1/9 [==>...........................] - ETA: 0s - loss: 0.0304 - accuracy: 0.9920\n",
            "Epoch 140: val_loss did not improve from 0.06166\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 0.0328 - accuracy: 0.9897 - val_loss: 0.0683 - val_accuracy: 0.9860\n",
            "Epoch 141/3500\n",
            "1/9 [==>...........................] - ETA: 0s - loss: 0.0298 - accuracy: 0.9920\n",
            "Epoch 141: val_loss did not improve from 0.06166\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.0338 - accuracy: 0.9899 - val_loss: 0.0791 - val_accuracy: 0.9818\n",
            "Epoch 142/3500\n",
            "1/9 [==>...........................] - ETA: 0s - loss: 0.0263 - accuracy: 0.9940\n",
            "Epoch 142: val_loss did not improve from 0.06166\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 0.0349 - accuracy: 0.9901 - val_loss: 0.0631 - val_accuracy: 0.9860\n",
            "Epoch 143/3500\n",
            "1/9 [==>...........................] - ETA: 0s - loss: 0.0318 - accuracy: 0.9940\n",
            "Epoch 143: val_loss did not improve from 0.06166\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 0.0337 - accuracy: 0.9899 - val_loss: 0.0624 - val_accuracy: 0.9865\n",
            "Epoch 144/3500\n",
            "1/9 [==>...........................] - ETA: 0s - loss: 0.0244 - accuracy: 0.9920\n",
            "Epoch 144: val_loss did not improve from 0.06166\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.0324 - accuracy: 0.9890 - val_loss: 0.0672 - val_accuracy: 0.9865\n",
            "Epoch 145/3500\n",
            "1/9 [==>...........................] - ETA: 0s - loss: 0.0404 - accuracy: 0.9860\n",
            "Epoch 145: val_loss did not improve from 0.06166\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 0.0322 - accuracy: 0.9897 - val_loss: 0.0626 - val_accuracy: 0.9865\n",
            "Epoch 146/3500\n",
            "1/9 [==>...........................] - ETA: 0s - loss: 0.0275 - accuracy: 0.9860\n",
            "Epoch 146: val_loss did not improve from 0.06166\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.0341 - accuracy: 0.9894 - val_loss: 0.0679 - val_accuracy: 0.9851\n",
            "Epoch 147/3500\n",
            "1/9 [==>...........................] - ETA: 0s - loss: 0.0371 - accuracy: 0.9920\n",
            "Epoch 147: val_loss did not improve from 0.06166\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 0.0350 - accuracy: 0.9890 - val_loss: 0.0634 - val_accuracy: 0.9865\n",
            "Epoch 148/3500\n",
            "1/9 [==>...........................] - ETA: 0s - loss: 0.0147 - accuracy: 0.9940\n",
            "Epoch 148: val_loss did not improve from 0.06166\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 0.0340 - accuracy: 0.9901 - val_loss: 0.0622 - val_accuracy: 0.9855\n",
            "Epoch 149/3500\n",
            "1/9 [==>...........................] - ETA: 0s - loss: 0.0376 - accuracy: 0.9940\n",
            "Epoch 149: val_loss did not improve from 0.06166\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 0.0334 - accuracy: 0.9890 - val_loss: 0.0654 - val_accuracy: 0.9851\n",
            "Epoch 150/3500\n",
            "1/9 [==>...........................] - ETA: 0s - loss: 0.0384 - accuracy: 0.9820\n",
            "Epoch 150: val_loss did not improve from 0.06166\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.0342 - accuracy: 0.9883 - val_loss: 0.0632 - val_accuracy: 0.9865\n",
            "Epoch 151/3500\n",
            "1/9 [==>...........................] - ETA: 0s - loss: 0.0144 - accuracy: 0.9960\n",
            "Epoch 151: val_loss did not improve from 0.06166\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 0.0319 - accuracy: 0.9897 - val_loss: 0.0641 - val_accuracy: 0.9869\n",
            "Epoch 152/3500\n",
            "1/9 [==>...........................] - ETA: 0s - loss: 0.0242 - accuracy: 0.9920\n",
            "Epoch 152: val_loss did not improve from 0.06166\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.0325 - accuracy: 0.9894 - val_loss: 0.0636 - val_accuracy: 0.9855\n",
            "Epoch 153/3500\n",
            "1/9 [==>...........................] - ETA: 0s - loss: 0.0203 - accuracy: 0.9900\n",
            "Epoch 153: val_loss did not improve from 0.06166\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 0.0327 - accuracy: 0.9890 - val_loss: 0.0627 - val_accuracy: 0.9846\n",
            "Epoch 154/3500\n",
            "1/9 [==>...........................] - ETA: 0s - loss: 0.0229 - accuracy: 0.9900\n",
            "Epoch 154: val_loss did not improve from 0.06166\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.0351 - accuracy: 0.9892 - val_loss: 0.0653 - val_accuracy: 0.9851\n",
            "Epoch 155/3500\n",
            "1/9 [==>...........................] - ETA: 0s - loss: 0.0490 - accuracy: 0.9840\n",
            "Epoch 155: val_loss did not improve from 0.06166\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.0332 - accuracy: 0.9897 - val_loss: 0.0635 - val_accuracy: 0.9851\n",
            "Epoch 156/3500\n",
            "1/9 [==>...........................] - ETA: 0s - loss: 0.0171 - accuracy: 0.9920\n",
            "Epoch 156: val_loss did not improve from 0.06166\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 0.0330 - accuracy: 0.9892 - val_loss: 0.0640 - val_accuracy: 0.9865\n",
            "Epoch 157/3500\n",
            "1/9 [==>...........................] - ETA: 0s - loss: 0.0539 - accuracy: 0.9820\n",
            "Epoch 157: val_loss did not improve from 0.06166\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.0343 - accuracy: 0.9883 - val_loss: 0.0649 - val_accuracy: 0.9860\n",
            "Epoch 158/3500\n",
            "1/9 [==>...........................] - ETA: 0s - loss: 0.0129 - accuracy: 0.9960\n",
            "Epoch 158: val_loss did not improve from 0.06166\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.0319 - accuracy: 0.9892 - val_loss: 0.0649 - val_accuracy: 0.9855\n",
            "Epoch 159/3500\n",
            "1/9 [==>...........................] - ETA: 0s - loss: 0.0447 - accuracy: 0.9880\n",
            "Epoch 159: val_loss did not improve from 0.06166\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.0323 - accuracy: 0.9890 - val_loss: 0.0669 - val_accuracy: 0.9860\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "DHzyFwLJxyvR",
        "outputId": "c70007ad-1961-4f32-87b6-9ea4c355ff0b"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/checkpoint/aaaa'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "IuUIACODx0sn"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}