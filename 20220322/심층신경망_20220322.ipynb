{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c6d98f99",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 28, 28)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow import keras\n",
    "(x_train,y_train),(x_target,y_target) =  keras.datasets.fashion_mnist.load_data()\n",
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "adf27da4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 784)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 2차원 만 허용\n",
    "x_train_2d = x_train.reshape(-1,28*28)\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "ss = StandardScaler()\n",
    "x_train_scaled =  ss.fit_transform(x_train_2d)\n",
    "x_train_scaled.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6e7e60a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#학습용을 8:2로 분리\n",
    "from sklearn.model_selection import train_test_split\n",
    "x_train_sc, x_target_sc, y_train_sc, y_target_sc  = train_test_split(\n",
    "    x_train_scaled,y_train, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1985b842",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((48000, 784), (48000,))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train_sc.shape, y_train_sc.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "dbad0aee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 은닉층\n",
    "dense1 = keras.layers.Dense(100,activation='sigmoid', input_shape=(28*28,))\n",
    "# 출력층\n",
    "dense2 = keras.layers.Dense(10,activation='softmax')\n",
    "model = keras.Sequential([dense1,dense2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "36375fb5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 100)               78500     \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 10)                1010      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 79,510\n",
      "Trainable params: 79,510\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ac556cb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.Sequential([\n",
    "    keras.layers.Dense(100,activation='sigmoid', input_shape=(28*28,)),\n",
    "    keras.layers.Dense(10,activation='softmax')\n",
    "],name=\"패션 MNIST모델\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b7057a3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"패션 MNIST모델\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_4 (Dense)             (None, 100)               78500     \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 10)                1010      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 79,510\n",
      "Trainable params: 79,510\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "76914456",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.Sequential()\n",
    "model.add(keras.layers.Dense(500,activation='sigmoid', input_shape=(28*28,)))\n",
    "# model.add(keras.layers.Dense(400,activation='sigmoid'))\n",
    "# model.add(keras.layers.Dense(300,activation='sigmoid'))\n",
    "# model.add(keras.layers.Dense(200,activation='sigmoid'))\n",
    "# model.add(keras.layers.Dense(100,activation='sigmoid'))\n",
    "model.add(keras.layers.Dense(10,activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "7da2aa98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_11\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_54 (Dense)            (None, 500)               392500    \n",
      "                                                                 \n",
      " dense_55 (Dense)            (None, 10)                5010      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 397,510\n",
      "Trainable params: 397,510\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "8b342aa3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "1500/1500 [==============================] - 9s 6ms/step - loss: 0.4579 - accuracy: 0.8354\n",
      "Epoch 2/5\n",
      "1500/1500 [==============================] - 9s 6ms/step - loss: 0.3458 - accuracy: 0.8750\n",
      "Epoch 3/5\n",
      "1500/1500 [==============================] - 9s 6ms/step - loss: 0.3036 - accuracy: 0.8906\n",
      "Epoch 4/5\n",
      "1500/1500 [==============================] - 8s 5ms/step - loss: 0.2705 - accuracy: 0.9032\n",
      "Epoch 5/5\n",
      "1500/1500 [==============================] - 8s 5ms/step - loss: 0.2443 - accuracy: 0.9094\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1964d365fa0>"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(loss='sparse_categorical_crossentropy', metrics='accuracy')\n",
    "model.fit(x_train_sc,y_train_sc,epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "34a372c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 초기 인공지능의 신경망의 은닉층에 많이 사용된 활성화 함수는 시그모이드\n",
    "# 오른쪽이나 왼쪽으로 갈수록 0과 1에 가까운 수를 반환하기때문에 함수 적용 효과가 떨어지고 결과값도 \n",
    "# 별로 차이가 안남\n",
    "# 가중치를 즉각적으로 반영하기 위해.. 렐루 함수\n",
    "# 렐루 함수는 이미지 처리에 좋은 성능을 낸다\n",
    "\n",
    "# Flatten 층은 데이터를 1차원으로 펼쳐서 입력을 시켜주는 층 : 은닉층 앞에 존재"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "c3410e23",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.Sequential()\n",
    "model.add(keras.layers.Flatten(input_shape=(28*28,)))\n",
    "model.add(keras.layers.Dense(500,activation='relu'))\n",
    "model.add(keras.layers.Dense(10,activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "9aca89d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_15\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " flatten_1 (Flatten)         (None, 784)               0         \n",
      "                                                                 \n",
      " dense_60 (Dense)            (None, 500)               392500    \n",
      "                                                                 \n",
      " dense_61 (Dense)            (None, 10)                5010      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 397,510\n",
      "Trainable params: 397,510\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "ac3f924d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "1500/1500 [==============================] - 10s 6ms/step - loss: 0.5437 - accuracy: 0.8289\n",
      "Epoch 2/5\n",
      "1500/1500 [==============================] - 9s 6ms/step - loss: 0.4262 - accuracy: 0.8702\n",
      "Epoch 3/5\n",
      "1500/1500 [==============================] - 9s 6ms/step - loss: 0.3849 - accuracy: 0.8831\n",
      "Epoch 4/5\n",
      "1500/1500 [==============================] - 9s 6ms/step - loss: 0.3618 - accuracy: 0.8925\n",
      "Epoch 5/5\n",
      "1500/1500 [==============================] - 9s 6ms/step - loss: 0.3501 - accuracy: 0.9008\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1964d6a98b0>"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(loss='sparse_categorical_crossentropy', metrics='accuracy')\n",
    "model.fit(x_train_sc,y_train_sc,epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "e4f602d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((12000, 784), (12000,))"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_target_sc.shape , y_target_sc.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "b8b8ebc0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "375/375 [==============================] - 1s 1ms/step - loss: 0.5907 - accuracy: 0.8727\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.590703547000885, 0.8727499842643738]"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(x_target_sc, y_target_sc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "e23e596f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 인공신경망..... 기본이.. 경사하강법(확율적 경사하강법)  기본만 사용할거면.... 머신러닝과 비슷하\n",
    "# SGDClassfiy (로지스틱회귀) ---: skelearn\n",
    "\n",
    "# 인공신경망 + 은닉층 + 은닉층 + n  --->  keras\n",
    "# 은닉층의 결과가 뉴런...->출력\n",
    "# 은닉층이 마지막 출력을 뜻하면 -> 출력층(활성화함수는 소프트맥스)\n",
    "# 그외 은닉층은 기본적으로 시그모이드 함수.... --> 이유는 선형회귀 의 식을 곡선으로 만들어서 \n",
    "# 다음 결과와 겹치지 않게 ....\n",
    "# 시그모이드의 단점은.... 값이 계속 증가할수록 변화가 거의 없어서... 어떤 상황을 즉각적으로 반영\n",
    "# 하지 못함..--> 렐루 함수 : 0보다 클때는 실제 값을 반영, 작을때는 전부 0으로 처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "752834f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 은닉층을 사용한 경우가 사용하지 않은 경우보다 약간 개선된것을 볼수 있음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "29d10831",
   "metadata": {},
   "outputs": [],
   "source": [
    "# compile() => 경사하강법.. RMSprop 알고리즘을 사용 --> 확율적 경사하강법\n",
    "# SGD ->확율적 경사하강법  학습율을 변경할수 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "0257f810",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'name': 'SGD',\n",
       " 'learning_rate': 0.01,\n",
       " 'decay': 0.0,\n",
       " 'momentum': 0.0,\n",
       " 'nesterov': False}"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = keras.Sequential()\n",
    "model.add(keras.layers.Flatten(input_shape=(28*28,)))\n",
    "model.add(keras.layers.Dense(500,activation='relu'))\n",
    "model.add(keras.layers.Dense(10,activation='softmax'))\n",
    "sgd = keras.optimizers.SGD()  # learning_rate': 0.01\n",
    "sgd.get_config()\n",
    "# model.compile(optimizer=sgd, loss='sparse_categorical_crossentropy', metrics='accuracy')\n",
    "# model.fit(x_train_sc,y_train_sc,epochs=5)\n",
    "\n",
    "# model.evaluate(x_target_sc, y_target_sc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "e07c903e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.5162 - accuracy: 0.8211\n",
      "Epoch 2/5\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.3769 - accuracy: 0.8675\n",
      "Epoch 3/5\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.3395 - accuracy: 0.8802\n",
      "Epoch 4/5\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.3147 - accuracy: 0.8884\n",
      "Epoch 5/5\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.2951 - accuracy: 0.8957\n",
      "375/375 [==============================] - 1s 1ms/step - loss: 0.3360 - accuracy: 0.8804\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.335997074842453, 0.8804166913032532]"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = keras.Sequential()\n",
    "model.add(keras.layers.Flatten(input_shape=(28*28,)))\n",
    "model.add(keras.layers.Dense(500,activation='relu'))\n",
    "model.add(keras.layers.Dense(10,activation='softmax'))\n",
    "# 모멘텀 살릴것\n",
    "sgd = keras.optimizers.SGD()  # sgd.get_config()\n",
    "model.compile(optimizer=sgd, loss='sparse_categorical_crossentropy', metrics='accuracy')\n",
    "model.fit(x_train_sc,y_train_sc,epochs=5)\n",
    "model.evaluate(x_target_sc, y_target_sc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "7673e8e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.5177 - accuracy: 0.8204\n",
      "Epoch 2/5\n",
      "1500/1500 [==============================] - 4s 2ms/step - loss: 0.3777 - accuracy: 0.8667\n",
      "Epoch 3/5\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.3387 - accuracy: 0.8800\n",
      "Epoch 4/5\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.3144 - accuracy: 0.8873\n",
      "Epoch 5/5\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.2952 - accuracy: 0.8956\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.3335 - accuracy: 0.8839\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.3335099220275879, 0.8839166760444641]"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#네스테로프 모멘텀: 속도  , 모멘텀 최적화를 2번 반복해서 구현\n",
    "model = keras.Sequential()\n",
    "model.add(keras.layers.Flatten(input_shape=(28*28,)))\n",
    "model.add(keras.layers.Dense(500,activation='relu'))\n",
    "model.add(keras.layers.Dense(10,activation='softmax'))\n",
    "\n",
    "# sgd = keras.optimizers.SGD(momentum=0.9, nesterov=True)  # learning_rate 기본 0.01  momentum=0\n",
    "sgd = keras.optimizers.SGD() \n",
    "model.compile(optimizer=sgd, loss='sparse_categorical_crossentropy', metrics='accuracy')\n",
    "model.fit(x_train_sc,y_train_sc,epochs=5)\n",
    "model.evaluate(x_target_sc, y_target_sc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "3f6654ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'name': 'Adagrad',\n",
       " 'learning_rate': 0.001,\n",
       " 'decay': 0.0,\n",
       " 'initial_accumulator_value': 0.1,\n",
       " 'epsilon': 1e-07}"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 모델이 최적점에 가까이 갈수록 학습율을(러닝레이트) 낮출수있고, 이렇게하면 안정적으로 최적점에 도착할 가능성이 높다\n",
    "# 적응적 학습율이라고 한다.\n",
    "# 장점 : 매개변수 튜닝을 안해도 된다.\n",
    "# Adagrad 와 RMSProps \n",
    "model = keras.Sequential()\n",
    "model.add(keras.layers.Flatten(input_shape=(28*28,)))\n",
    "model.add(keras.layers.Dense(500,activation='relu'))\n",
    "model.add(keras.layers.Dense(10,activation='softmax'))\n",
    "\n",
    "adagrad = keras.optimizers.Adagrad()  # learning_rate': 0.001  momentum=0\n",
    "adagrad.get_config()\n",
    "# model.compile(optimizer=adagrad, loss='sparse_categorical_crossentropy', metrics='accuracy')\n",
    "# model.fit(x_train_sc,y_train_sc,epochs=5)\n",
    "# model.evaluate(x_target_sc, y_target_sc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "acaaed17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.4869 - accuracy: 0.8361\n",
      "Epoch 2/5\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.3584 - accuracy: 0.8732\n",
      "Epoch 3/5\n",
      "1500/1500 [==============================] - 5s 4ms/step - loss: 0.3243 - accuracy: 0.8830\n",
      "Epoch 4/5\n",
      "1500/1500 [==============================] - 5s 4ms/step - loss: 0.2970 - accuracy: 0.8939\n",
      "Epoch 5/5\n",
      "1500/1500 [==============================] - 6s 4ms/step - loss: 0.2736 - accuracy: 0.9021\n",
      "375/375 [==============================] - 1s 1ms/step - loss: 0.3809 - accuracy: 0.8780\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.3809492886066437, 0.878000020980835]"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = keras.Sequential()\n",
    "model.add(keras.layers.Flatten(input_shape=(28*28,)))\n",
    "model.add(keras.layers.Dense(500,activation='relu'))\n",
    "model.add(keras.layers.Dense(10,activation='softmax'))\n",
    "\n",
    "# 모멘텀 최적화와 RMSprop 의 장점을 묶은게.. Adam \n",
    "adam = keras.optimizers.Adam()  # learning_rate 기본 0.01  momentum=0\n",
    "model.compile(optimizer=adam, loss='sparse_categorical_crossentropy', metrics='accuracy')\n",
    "model.fit(x_train_sc,y_train_sc,epochs=5)\n",
    "model.evaluate(x_target_sc, y_target_sc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a405d1ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SGD\n",
    "# 기본경사 하강법의 옵티마이져\n",
    "# learning_rate  0.01\n",
    "# momentum 값을 0이상을 주면 모멘텀 최적화를 수행\n",
    "# nesterov 매개변수를 True로 설정하면 네스테로브 모멘텀 최적화를 수행"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad8d9663",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adagrad\n",
    "# learning_rate  0.001\n",
    "# 그레디언트 제곱하여 누적하여 학습율을 나눔\n",
    "# initail_accumulator_value 기본값은 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c5577f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# RMSProp \n",
    "# learning_rate  0.001\n",
    "# Adagrad처럼 그레디언트 제곱을 학습율로 나누지만 최근의 그레디언트를 사용하기위해 지수감소를 사용\n",
    "# rho 감소비율 기본값은 0.9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "439910ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adam  : 대체적으로 가장 높은 최적화를 수행하는 알고리즘\n",
    "# learning_rate  0.001\n",
    "# 모멘텀을 최적화하기위해서 그레디언트 지수를 감소하는데 평균을 조절하기 위해 beta_1매개변수  0.9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63700bb8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
