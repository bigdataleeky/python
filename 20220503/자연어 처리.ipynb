{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "974de79b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 자연어 처리 NLP(Natural language processing)\n",
    "# 응용\n",
    "    # 언어번역, 댓글분석->예측, 쳇봇, 시나 소설 또는 뉴스기사를 대략적으로 만들기\n",
    "    \n",
    "# 실습.... - 기존의 제공하는 데이터셋을 이용  IMDB 영화 평점 데이터셋(영어)\n",
    "# 문장을 분석하는데 있어 특징\n",
    "# NOISE가 심하다.\n",
    "# 형태소 분석\n",
    "# 다양한 언어의 특성\n",
    "# 신경망에 입력--> 수치로 변환"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "40040c3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 텍스트 데이터를 변환하는 과정\n",
    "# 1. 말뭉치(corpus)\n",
    "# i love you but ... ... ... ... .. .. .. .. ...\n",
    "# 2. 단어 수집(괄호는 빈도수)\n",
    "# i(2), love(100)\n",
    "# 3. 파이썬 딕션너리 구조로 표현  {'i':2, 'love':100 ....}\n",
    "# 4. 텍스트를 숫자형태의 코드로 변환 \n",
    "# i love you   -> [1 2 3]\n",
    "# i have car   -> [1 4 5]\n",
    "# the car is bufifule -> [6 5 7 8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "271e3083",
   "metadata": {},
   "outputs": [],
   "source": [
    "# onehot 으로 표현.... 단어들은 수치가 아니여서 스케일을 못해... oneHot 표현.... \n",
    "# 단점 : 메모리낭비..(단어가 기하급수적으로 늘어나면.... )\n",
    "# 단어사이의 연관관계를표현 못함\n",
    "# --> 단어 임베딩..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4a8cc78d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "첫번째 댓글Once again Mr. Costner has dragged out a movie for far longer than necessary. Aside from the terrific sea rescue sequences, of which there are very few I just did not care about any of the characters. Most of us have ghosts in the closet, and Costner's character are realized early on, and then forgotten until much later, by which time I did not care. The character we should really care about is a very cocky, overconfident Ashton Kutcher. The problem is he comes off as kid who thinks he's better than anyone else around him and shows no signs of a cluttered closet. His only obstacle appears to be winning over Costner. Finally when we are well past the half way point of this stinker, Costner tells us all about Kutcher's ghosts. We are told why Kutcher is driven to be the best with no prior inkling or foreshadowing. No magic here, it was all I could do to keep from turning it off an hour in. 평가 : neg\n",
      "마지막 댓글When I saw this movie for the first time I was both surprised and a little shocked by the blatant vibrance of the story. It is a very artistic drama with incredible special effects, spectacular acting, not to mention a very excellent job in the makeup department. Jennifer Lopez has pulled herself out of past roles that dug into her career with this movie, portraying a very sensitive child psychologist who works with a team of engineers to enter the minds of comatose patients to treat them. Vincent D'onofrio played amazingly well. His portrayal of a sadist serial killer was perfect to a T. The sheer emotion conveyed by his performance is astounding. Vince Vaughn isn't my favorite, but still performed exceptionally well. The symbolism and artistry was intriguing and titillating, sometimes surprising, and other times shocking. Overall, I say this is a wonderful movie, with excellent acting and beautiful artwork. 평가 : pos\n"
     ]
    }
   ],
   "source": [
    "# IMDB 원본 데이터\n",
    "import os\n",
    "# 데이터 로드\n",
    "x=[]; y=[]\n",
    "root_path = 'D:/이규영/ml/aclImdb/aclImdb/test'\n",
    "for path in os.listdir(root_path):\n",
    "    if os.path.isdir(root_path+'/'+path):\n",
    "        for fileName in os.listdir(root_path+'/'+path):\n",
    "            with open(root_path+'/'+path+'/'+fileName, 'r', encoding='utf-8') as f:\n",
    "                x.append(f.read()); y.append(path)\n",
    "                \n",
    "print(f\"첫번째 댓글{x[0]} 평가 : {y[0]}\"); print(f\"마지막 댓글{x[-1]} 평가 : {y[-1]}\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5ed09d51",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 텐서플로우가 제공하는 데이터는 사용하기 좋게 미리 가공한 데이터\n",
    "from tensorflow.keras.datasets import imdb\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Flatten, Embedding\n",
    "from tensorflow.keras import preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d3c8e11f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/imdb.npz\n",
      "17465344/17464789 [==============================] - 0s 0us/step\n",
      "17473536/17464789 [==============================] - 0s 0us/step\n",
      "(25000,) (25000,)\n",
      "[1, 14, 22, 16, 43, 530, 973, 1622, 1385, 65, 458, 4468, 66, 3941, 4, 173, 36, 256, 5, 25, 100, 43, 838, 112, 50, 670, 2, 9, 35, 480, 284, 5, 150, 4, 172, 112, 167, 2, 336, 385, 39, 4, 172, 4536, 1111, 17, 546, 38, 13, 447, 4, 192, 50, 16, 6, 147, 2025, 19, 14, 22, 4, 1920, 4613, 469, 4, 22, 71, 87, 12, 16, 43, 530, 38, 76, 15, 13, 1247, 4, 22, 17, 515, 17, 12, 16, 626, 18, 2, 5, 62, 386, 12, 8, 316, 8, 106, 5, 4, 2223, 5244, 16, 480, 66, 3785, 33, 4, 130, 12, 16, 38, 619, 5, 25, 124, 51, 36, 135, 48, 25, 1415, 33, 6, 22, 12, 215, 28, 77, 52, 5, 14, 407, 16, 82, 2, 8, 4, 107, 117, 5952, 15, 256, 4, 2, 7, 3766, 5, 723, 36, 71, 43, 530, 476, 26, 400, 317, 46, 7, 4, 2, 1029, 13, 104, 88, 4, 381, 15, 297, 98, 32, 2071, 56, 26, 141, 6, 194, 7486, 18, 4, 226, 22, 21, 134, 476, 26, 480, 5, 144, 30, 5535, 18, 51, 36, 28, 224, 92, 25, 104, 4, 226, 65, 16, 38, 1334, 88, 12, 16, 283, 5, 16, 4472, 113, 103, 32, 15, 16, 5345, 19, 178, 32]\n"
     ]
    }
   ],
   "source": [
    "# 텐서플로가 제공하는 간소화된 imdb 데이터 읽기  사전의 갯수를 지정할수 있음\n",
    "(x_train,y_train),(x_target,y_target) =imdb.load_data(num_words=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "bea6c4f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(25000,) (25000,)\n",
      "[1, 14, 22, 16, 43, 530, 973, 1622, 1385, 65, 458, 4468, 66, 3941, 4, 173, 36, 256, 5, 25, 100, 43, 838, 112, 50, 670, 2, 9, 35, 480, 284, 5, 150, 4, 172, 112, 167, 2, 336, 385, 39, 4, 172, 4536, 1111, 17, 546, 38, 13, 447, 4, 192, 50, 16, 6, 147, 2025, 19, 14, 22, 4, 1920, 4613, 469, 4, 22, 71, 87, 12, 16, 43, 530, 38, 76, 15, 13, 1247, 4, 22, 17, 515, 17, 12, 16, 626, 18, 2, 5, 62, 386, 12, 8, 316, 8, 106, 5, 4, 2223, 5244, 16, 480, 66, 3785, 33, 4, 130, 12, 16, 38, 619, 5, 25, 124, 51, 36, 135, 48, 25, 1415, 33, 6, 22, 12, 215, 28, 77, 52, 5, 14, 407, 16, 82, 2, 8, 4, 107, 117, 5952, 15, 256, 4, 2, 7, 3766, 5, 723, 36, 71, 43, 530, 476, 26, 400, 317, 46, 7, 4, 2, 1029, 13, 104, 88, 4, 381, 15, 297, 98, 32, 2071, 56, 26, 141, 6, 194, 7486, 18, 4, 226, 22, 21, 134, 476, 26, 480, 5, 144, 30, 5535, 18, 51, 36, 28, 224, 92, 25, 104, 4, 226, 65, 16, 38, 1334, 88, 12, 16, 283, 5, 16, 4472, 113, 103, 32, 15, 16, 5345, 19, 178, 32] 1\n"
     ]
    }
   ],
   "source": [
    "print(x_train.shape, y_train.shape)\n",
    "print(x_train[0], y_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "76d1e533",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1], dtype=int64)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "np.unique(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "af3b483b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "88584 88584\n"
     ]
    }
   ],
   "source": [
    "# 단어 빈도수, 빈도수 단어로 변환하는 기준표 -- 노래데이터 기준표를 상기하면서....\n",
    "word_index =  imdb.get_word_index()  # 단어:빈도수\n",
    "index_word = {value:key for key,value in  word_index.items()}  # 빈도수:단어\n",
    "print(len(word_index), len(index_word))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "d53cde79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'l'/voorhees'/artbox/copywrite/pipe's/wheelers/sics/transacting/chicatillo/ev/urrrghhh/airsoft/nemesis'/guard's/'solve'/odilon/baywatch'/heralding/lubricated/percival/"
     ]
    }
   ],
   "source": [
    "# 크기가아니라.데이터의 집합중에 빈도수가 가장많은 상위 20의 데이터 확인\n",
    "sorted(index_word.items())[::-1][:20]\n",
    "for key,value in  sorted(index_word.items(),reverse=True)[:20]:\n",
    "    print(value,end='/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ce74c4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 단어임베딩\n",
    "# 단어를 저차원 공간의 벡터로 표현\n",
    "# 단어는 수백차원을 사용, 밀집벡터, 신경망 학습을 통해 알아냄\n",
    "# korea->seoul  spain->madrid,  japan ->toko ... "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
